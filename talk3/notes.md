# Talk 3: Linear regression

## Theory

- **Essential**: Bach sections 3.1, 3.2, 3.3, 3.10.
- **Nice to have**: 3.6, 3.9.
- **Not so important**: 3.4, 3.5, 3.7, 3.8.

## Code
- Generate some data pairs $(x_{i}, f(x_{i}))$ with $f \colon \mathbb{R} \to \mathbb{R}$ and assemble into `numpy` arrays.
- Show how to use `numpy` to do the matrix calculations needed in Proposition 3.1 of Bach and fit the OLS estimator.
- Plot using `matplotlib`
- (more advanced) Use the more numerically stable approaches in section 3.3.3 of Bach: (1) $QR$ factorisation can be done using numpy; (2) gradient descent should be postponed to talk 4, in which we actually introduce gradient descent.


